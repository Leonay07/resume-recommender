{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Project Overview","text":""},{"location":"#goal","title":"Goal","text":"<p>This system helps job seekers discover relevant roles by comparing their resume against live job listings. Users upload a PDF/DOCX resume, specify optional search preferences, and receive explainable recommendations. The project delivers an end\u2011to\u2011end system deployed on Hugging Face Spaces and a microservice stack runnable via Docker Compose.</p>"},{"location":"#system-components","title":"System Components","text":"Module Technology Description Frontend React + Vite + TypeScript Routes across Landing/Search/Result/Job pages, submits forms, and renders explanations. Backend FastAPI + python-multipart Handles file uploads, RapidAPI requests, resume parsing, scoring, caching, and static assets. ML ResumeParser + TF\u2013IDF + heuristic engine Extracts skills/intent and scores jobs across five weighted dimensions."},{"location":"#end-to-end-workflow","title":"End-to-End Workflow","text":"<ol> <li>Upload &amp; Preferences \u2013 the user uploads a PDF/DOCX resume and optionally sets title, location, and experience preferences.</li> <li>Resume Parsing \u2013 FastAPI writes the file to a temp path and <code>ResumeParser</code> extracts text, sections, skills, and inferred intent.</li> <li>Job Fetching \u2013 <code>job_fetcher</code> calls RapidAPI\u2019s JSearch endpoint, paginates up to three pages, deduplicates <code>(title, company)</code>, and returns descriptions with apply links.</li> <li>Hybrid Scoring \u2013 <code>nlp_model_stub.recommend_jobs</code> combines skill overlap, TF\u2013IDF similarity, role intent, experience alignment, and location match to produce weighted scores and readable summaries.</li> <li>Caching &amp; Pagination \u2013 the ranked list is cached in <code>backend/cache.json</code>; <code>/match</code> returns the top 10 while <code>/match/more</code> streams the remainder to the frontend.</li> <li>Visualization \u2013 React/Vite displays job cards, highlights overlapping skills, and surfaces apply links. Requests can be re-run with different parameters without restarting the API.</li> </ol>"},{"location":"#development-deployment-paths","title":"Development &amp; Deployment Paths","text":"<ul> <li>Local development uses Poetry + npm for rapid iteration; <code>setup_local.sh</code> installs both environments.</li> <li>Containerized demo uses Docker Compose (frontend + backend + MLflow) or the single Dockerfile for Hugging Face.</li> <li>Documentation &amp; CI: MkDocs provides this documentation site; GitHub Actions (<code>ci.yml</code> + <code>docs.yml</code>) run lint/tests and deploy docs to <code>gh-pages</code>.</li> </ul>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#system-diagram","title":"System Diagram","text":"<pre><code>[Vite Frontend]  &lt;--HTTP--&gt;  [FastAPI Backend]\n     |                            |\n     | upload + form data         |  parse resume + fetch jobs\n     |                            v\n     |                       [ResumeParser]\n     |                            |\n     |                       [Hybrid Scorer] &lt;-- [Job Fetcher -&gt; RapidAPI JSearch]\n     |                            |\n     -----------&gt; [cache.json pagination]\n</code></pre> <ul> <li>Frontend renders React routes, posts multipart forms, and fetches <code>/jobs/random</code>, <code>/jobs/search</code>, <code>/match</code>, <code>/match/more</code>.</li> <li>Backend (<code>backend/app.py</code>) manages uploads, temporary storage, static assets, and caches recommendations. It calls <code>job_fetcher.py</code> for RapidAPI requests and <code>nlp_model_stub.py</code> for scoring.</li> <li>ML Layer leverages <code>nlp_model/resume_parser.py</code>, <code>skills_dict.py</code>, <code>extract_job_skills_from_list.py</code>, and <code>tfidf_matcher.py</code>.</li> <li>Data Layer relies on live RapidAPI responses; the only on-disk artifacts are transient temp files and <code>cache.json</code>. Configuration comes from <code>backend/.env</code> or environment variables.</li> </ul>"},{"location":"architecture/#runtime-flow","title":"Runtime Flow","text":"<ol> <li>Upload \u2013 the frontend sends a multipart request to <code>/match</code> containing the resume file and form inputs.</li> <li>Resume Parsing \u2013 <code>ResumeParser</code> detects sections (skills/experience/education/projects/summary), extracts skills, and infers target roles.</li> <li>Job Fetching \u2013 <code>fetch_jobs_from_api</code> builds a \u201ctitle in location\u201d query, loops up to 3 pages, deduplicates <code>(title, company)</code>, and retains essential metadata.</li> <li>Hybrid Scoring \u2013 <code>recommend_jobs</code> calculates: </li> <li>skill overlap (40% weight),</li> <li>TF\u2013IDF similarity (25%),</li> <li>role intent match (15%),</li> <li>experience alignment (10%),</li> <li>location match or remote allowance (10%).    It returns scores, summaries, keyword highlights, and apply links.</li> <li>Caching \u2013 results persist in <code>cache.json</code> so <code>/match/more</code> can stream the remainder without recomputing.</li> <li>Explainability &amp; Logging \u2013 debug logs print per-job scores, and when <code>MLFLOW_TRACKING_URI</code> is set, metrics are pushed to MLflow.</li> </ol>"},{"location":"architecture/#key-design-choices","title":"Key Design Choices","text":"<ul> <li>Secure uploads \u2013 use <code>tempfile.NamedTemporaryFile</code> and delete files immediately after parsing.</li> <li>Graceful fallbacks \u2013 optional location/experience fields default to empty strings; parser falls back to \u201cother\u201d section when headers are missing.</li> <li>JSearch filtering \u2013 rely on RapidAPI\u2019s filtering to avoid brittle client-side substring checks; only deduplicate and cap the number of results.</li> <li>Explainable output \u2013 each recommendation includes a short summary (skills match %, location match, etc.) plus the top overlapping skills (<code>keywords</code>).</li> <li>Microservices readiness \u2013 Compose separates front/back-end and MLflow so each service can scale or be replaced independently.</li> <li>Deployment parity \u2013 the root <code>Dockerfile</code> mirrors the backend container used in Compose, ensuring Hugging Face behaves the same as local builds.</li> </ul>"},{"location":"architecture/#testing-observability","title":"Testing &amp; Observability","text":"<ul> <li><code>tests/test_resume_parser.py</code> validates section parsing and skill extraction.</li> <li><code>tests/test_recommend_jobs.py</code> ensures skill-aligned jobs outrank unrelated ones and that the recommender returns complete metadata.</li> <li>Logging is centralized via <code>logging.basicConfig</code> in <code>backend/app.py</code>; <code>job_fetcher.py</code> and <code>nlp_model_stub.py</code> emit informational statements for debugging RapidAPI queries and scoring breakdowns.</li> <li>MLflow logging can be toggled by setting <code>MLFLOW_TRACKING_URI</code> (Compose does this automatically).</li> </ul>"},{"location":"architecture/#test-checklist","title":"Test Checklist","text":"<ul> <li>Job API: inspect <code>DEBUG</code> logs and ensure at least 10 results after deduping.</li> <li>Resume parsing: assert pdfplumber/python-docx extraction produces sections.</li> <li>Recommendation output: each item must include <code>score</code>, <code>summary</code>, and <code>keywords</code>.</li> <li>Cache pagination: simulate repeated <code>/match/more</code> calls to ensure cache reuse.</li> <li>Docker: run <code>docker build</code> + <code>docker run</code> locally and open <code>http://localhost:7860</code>.</li> </ul>"},{"location":"backend/api/","title":"Backend API Specification","text":"<p>The FastAPI app is defined in <code>backend/app.py</code> and exposes four public routes. The service entry point (used by Docker/HF) is:</p> <pre><code>uvicorn backend.app:app --host 0.0.0.0 --port 7860\n</code></pre> <p><code>backend/.env</code> (or environment variables) must include:</p> <pre><code>RAPID_API_KEY=...\nRAPID_API_HOST=jsearch.p.rapidapi.com\n</code></pre>"},{"location":"backend/api/#route-overview","title":"Route Overview","text":"Path Method Description <code>/jobs/random</code> GET Homepage feed sourced via <code>fetch_random_jobs</code> <code>/jobs/search</code> GET Fetch jobs filtered by title/location <code>/match</code> POST Upload a resume and return the top 10 recommendations <code>/match/more</code> GET Read <code>cache.json</code> for the remaining results"},{"location":"backend/api/#jobsrandom","title":"<code>/jobs/random</code>","text":"<ul> <li>Input: none</li> <li>Output: <code>{\"results\": [JobItem]}</code> with <code>title</code>, <code>company</code>, <code>location</code>, <code>description</code>, <code>apply_link</code>.</li> <li>Logic: fetch \u201cData Scientist\u201d jobs via RapidAPI and return a random sample of up to 10 entries.</li> </ul>"},{"location":"backend/api/#jobssearch","title":"<code>/jobs/search</code>","text":"<ul> <li>Query params: <code>title</code>, <code>location</code> (may be empty strings).</li> <li>Flow: construct <code>f\"{title} in {location}\"</code>, fetch up to <code>MAX_PAGES=3</code>, deduplicate <code>(title, company)</code>, and return the first <code>MIN_RESULTS</code> matches.</li> </ul>"},{"location":"backend/api/#match","title":"<code>/match</code>","text":"<ul> <li>Fields (multipart): <code>file</code> (UploadFile), <code>title</code>, <code>location</code> (optional), <code>experience</code> (optional).</li> <li>Flow:</li> <li>Store the file in a temp path and parse it via <code>ResumeParser</code>.</li> <li>Fetch jobs for the given title/location.</li> <li>Run <code>recommend_jobs</code> to score jobs and produce summaries.</li> <li>Cache the full list to <code>cache.json</code> and return the top 10.</li> </ul>"},{"location":"backend/api/#matchmore","title":"<code>/match/more</code>","text":"<ul> <li>Input: none.</li> <li>Output: entire cache from the last <code>/match</code> call; empty list if cache is missing or unreadable.</li> </ul>"},{"location":"backend/api/#data-contract","title":"Data Contract","text":"<pre><code>{\n  \"title\": \"Data Scientist\",\n  \"company\": \"Acme Corp\",\n  \"location\": \"Washington, DC\",\n  \"description\": \"...\",\n  \"apply_link\": \"https://...\",\n  \"score\": 0.82,\n  \"summary\": \"Skills Match (80%): Python, SQL...\",\n  \"keywords\": [\"python\", \"sql\"],\n  \"skills\": {\n    \"primary_skills\": [\"python\", \"sql\"],\n    \"all_skills\": [\"python\", \"sql\", \"aws\"],\n    \"skill_frequency\": {\"python\": 3}\n  }\n}\n</code></pre>"},{"location":"backend/api/#implementation-notes","title":"Implementation Notes","text":"<ul> <li><code>job_fetcher.py</code> handles pagination, deduplication, and random sampling (for <code>/jobs/random</code>). RapidAPI credentials are loaded via <code>python-dotenv</code>.</li> <li><code>cache.json</code> lives in <code>backend/</code> (the same directory as <code>app.py</code>). The API uses <code>pathlib</code> to ensure the file is resolved correctly whether running locally or inside Docker.</li> <li>CORS is configured to allow all origins since Hugging Face serves the frontend and backend from different domains during development.</li> </ul>"},{"location":"backend/api/#testing-tips","title":"Testing Tips","text":"<ol> <li>Mock RapidAPI responses to verify deduplication and job field normalization.</li> <li>Use synthetic resumes to ensure <code>recommend_jobs</code> returns skills, summaries, and keywords.</li> <li>Exercise <code>/match/more</code> after multiple <code>/match</code> calls to confirm caching works.</li> <li>In Docker, run <code>curl -F \"file=@resume.pdf\" -F \"title=...\" http://localhost:7860/match</code> to validate multipart uploads end-to-end.</li> </ol>"},{"location":"deployment/compose/","title":"Docker Compose Stack","text":"<p>This page describes the local microservice deployment that mirrors the cloud-grade architecture: individual containers for the FastAPI backend, Vite frontend, and an MLflow tracking server.</p>"},{"location":"deployment/compose/#services","title":"Services","text":"Service Image Ports Notes <code>backend</code> Built from <code>backend/Dockerfile</code> 8000 FastAPI API with Poetry deps; connects to MLflow via <code>MLFLOW_TRACKING_URI</code>. <code>frontend</code> Built from <code>frontend/Dockerfile</code> 5173 Serves the production Vite build via <code>serve</code>. Uses <code>VITE_API_BASE_URL</code> build arg to target <code>backend</code>. <code>mlflow</code> <code>ghcr.io/mlflow/mlflow</code> 5000 Logs experiments to <code>mlruns/</code> (mounted volume)."},{"location":"deployment/compose/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose v2+</li> <li><code>backend/.env</code> containing the RapidAPI credentials</li> <li>Optional: ensure <code>mlruns/</code> exists (it's ignored in Git and created automatically otherwise)</li> </ul>"},{"location":"deployment/compose/#usage","title":"Usage","text":"<pre><code>docker compose up --build\n</code></pre> <p>Once healthy: - Frontend: http://localhost:5173 - Backend API: http://localhost:8000 - MLflow UI: http://localhost:5500 (port mapped to 5000 inside the container)</p> <p>The backend container automatically sends lightweight metrics for each <code>/match</code> call to MLflow.</p>"},{"location":"deployment/compose/#environment-variables","title":"Environment Variables","text":"Variable Location Description <code>VITE_API_BASE_URL</code> frontend build arg Points the Vite bundle to the backend service (defaults to <code>http://backend:8000</code>). <code>MLFLOW_TRACKING_URI</code> backend service env Defaults to <code>http://mlflow:5000</code>; override if you host MLflow elsewhere. <p>To scale or replace services (e.g., swap MLflow for another tracker), edit <code>docker-compose.yml</code>.</p>"},{"location":"deployment/hf/","title":"Hugging Face Spaces Deployment","text":""},{"location":"deployment/hf/#goals","title":"Goals","text":"<ul> <li>Build frontend and backend with a single multi-stage Dockerfile.</li> <li>Run the resulting image on Hugging Face Spaces (Docker runtime).</li> <li>Keep port 7860 exposed for the React application.</li> </ul>"},{"location":"deployment/hf/#pre-deployment-checklist","title":"Pre-deployment Checklist","text":"<ul> <li>[ ] <code>backend/.env</code> already\u5305\u542b <code>RAPID_API_KEY</code> \u4e0e <code>RAPID_API_HOST</code></li> <li>[ ] \u672c\u5730\u8fd0\u884c <code>poetry run ruff check .</code>\u3001<code>poetry run pytest</code> \u5747\u901a\u8fc7</li> <li>[ ] \u4f7f\u7528 <code>docker compose up --build</code> \u672c\u5730\u9a8c\u8bc1\uff08\u53ef\u9009\uff0c\u786e\u4fdd\u524d\u540e\u7aef\u3001MLflow \u90fd\u6b63\u5e38\uff09</li> <li>[ ] Hugging Face Space \u9009\u62e9 Docker \u8fd0\u884c\u73af\u5883\uff0c\u5e76\u5728 \u201cSecrets\u201d \u4e2d\u914d\u7f6e <code>RAPID_API_KEY</code></li> <li>[ ] <code>huggingface.yaml</code> \u4f4d\u4e8e\u4ed3\u5e93\u6839\u76ee\u5f55</li> </ul>"},{"location":"deployment/hf/#build-run","title":"Build &amp; Run","text":"<pre><code># Local verification\ndocker build -t resume-recommender .\ndocker run --rm -p 7860:7860 --env-file backend/.env resume-recommender\n</code></pre> <ul> <li><code>.env</code> must define <code>RAPID_API_KEY</code> and <code>RAPID_API_HOST=jsearch.p.rapidapi.com</code>.</li> <li>Stage one (Node) produces the frontend assets copied into <code>backend/static/</code>.</li> <li>Stage two (Python 3.10) installs runtime deps via <code>pip install fastapi uvicorn[...] ... scikit-learn</code>.</li> </ul>"},{"location":"deployment/hf/#dockerfile-overview","title":"Dockerfile Overview","text":"Stage Base image Notes Frontend <code>node:18</code> <code>npm install &amp;&amp; npm run build</code> \u2192 <code>dist/</code> Backend <code>python:3.10-slim</code> Installs FastAPI/runtime deps directly via <code>pip install</code>, copies backend code + built assets Entrypoint <code>uvicorn backend.app:app --host 0.0.0.0 --port 7860</code>"},{"location":"deployment/hf/#hugging-face-config","title":"Hugging Face Config","text":"<p><code>huggingface.yaml</code></p> <pre><code>title: Resume Job Matcher\nsdk: docker\napp_port: 7860\n</code></pre> <p>Steps: 1. Create a Space with the Docker runtime and upload the repository. 2. Add <code>RAPID_API_KEY</code> (and other secrets) to the Space settings. 3. Trigger the build; once the Space shows <code>Running</code>, open the URL.</p>"},{"location":"deployment/hf/#validation-checklist","title":"Validation Checklist","text":"Step Expectation Build Logs complete without errors and the image finishes building UI Visiting the Space URL loads the React app Resume upload <code>/match</code> returns results and <code>cache.json</code> is created Load More <code>/match/more</code> returns the full cached list Logs <code>uvicorn</code> prints request logs for debugging"},{"location":"deployment/hf/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Missing API key: requests fail with 401\u2014verify Space secrets or <code>.env</code>; local <code>docker run</code> prints a warning.</li> <li>Static 404: ensure <code>npm run build</code> ran and the <code>dist/</code> folder was copied.</li> <li>CORS/upload errors: FastAPI already uses <code>allow_origins=\"*\"</code>; double-check frontend fetch URLs.</li> <li>Build timeout: keep dependencies lean (<code>pip install --no-cache-dir</code> is enabled) or restart the Space.</li> </ul>"},{"location":"model/interface/","title":"NLP Model Interface","text":""},{"location":"model/interface/#core-function","title":"Core Function","text":"<pre><code>def recommend_jobs(\n    resume_text: str,\n    job_list: list[dict],\n    title: str,\n    location: str,\n    experience: str,\n):\n    \"\"\"Return ranked job matches based on resume text and job list.\"\"\"\n</code></pre> <ul> <li>resume_text: plain text extracted by pdfplumber/python-docx.</li> <li>job_list: deduplicated job array returned by <code>fetch_jobs_from_api</code>.</li> <li>title/location/experience: user preferences from the frontend form; <code>experience</code> accepts \u201cNo preference\u201d.</li> </ul>"},{"location":"model/interface/#input-format","title":"Input Format","text":"<p>Each <code>job_list</code> element must include at least <code>title</code>, <code>company</code>, <code>location</code>, <code>description</code>, <code>apply_link</code>. The model should reuse this list rather than calling external APIs.</p>"},{"location":"model/interface/#output-format","title":"Output Format","text":"<p>Return an array sorted by score descending, shaped like:</p> <pre><code>{\n  \"title\": \"Machine Learning Engineer\",\n  \"company\": \"Meta\",\n  \"location\": \"DC\",\n  \"description\": \"...\",\n  \"score\": 0.87,\n  \"summary\": \"Your Python experience strongly matches...\",\n  \"keywords\": [\"python\", \"aws\"],\n  \"evidence_image\": null,\n  \"apply_link\": \"https://...\"\n}\n</code></pre> <ul> <li><code>score</code> must be normalized to [0, 1].</li> <li>Optional fields: <code>summary</code>, <code>keywords</code>, <code>evidence_image</code> (URL or <code>data:image/png;base64,...</code>).</li> <li>Return \u2264 10 entries; use <code>[]</code> when nothing matches.</li> </ul>"},{"location":"model/interface/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Resume parsing: use <code>ResumeParser</code> to split sections, extract skills, and infer intent.</li> <li>Skill matching: share <code>skills_dict</code>, run <code>extract_job_skills_from_list</code> on job descriptions, and intersect with user skills.</li> <li>Semantic matching: leverage <code>tfidf_matcher.compute_tfidf_scores</code>, scaling scores for interpretability.</li> <li>Experience/location: regex JD text for \u201cX years\u201d and state abbreviations with tolerance for variants.</li> <li>Explainability: craft <code>summary</code> strings such as \u201cSkills Match (xx%): ...\u201d using the strongest signal.</li> </ol>"},{"location":"model/interface/#backend-integration","title":"Backend Integration","text":"<ul> <li><code>app.py</code> calls <code>recommend_jobs</code> inside <code>/match</code> and handles caching; the model should not write files.</li> <li>If the model raises exceptions, FastAPI catches them and returns <code>{\"error\": \"...\"}</code>\u2014handle edge cases (empty job list, parsing issues) internally when possible.</li> </ul>"},{"location":"model/interface/#testing-baseline","title":"Testing Baseline","text":"<ul> <li>Mock <code>job_list</code> inputs to ensure the return schema is stable.</li> <li>Add unit tests for \u201cNo preference\u201d experience, remote roles, and state abbreviations.</li> <li>Return an empty list (not an exception) when <code>job_list</code> is empty.</li> </ul>"},{"location":"model/interface/#logging-telemetry","title":"Logging &amp; Telemetry","text":"<p>When <code>MLFLOW_TRACKING_URI</code> is set, <code>recommend_jobs</code> automatically sends lightweight metrics (jobs fetched/returned, average score, query context) to MLflow via REST. This is optional and primarily used in the Docker Compose stack, but it can be pointed to any tracking server.</p>"}]}